<!doctype html>
<html lang="en" class="no-js">

<head>
    <meta charset="utf-8">
    <!-- begin SEO -->
    <title>Jieming Cui</title>

    <meta property="og:locale" content="en">
    <meta property="og:site_name" content="Jieming Cui">
    <meta property="og:title" content="Jieming Cui">

    <link rel="canonical" href="https://jiemingcui.github.io/">
    <meta property="og:url" content="https://jiemingcui.github.io/">

    <meta property="og:description" content="PhD student in Peking University. Focusing on computer vision, robotics, and biology.">

    <!-- <meta name="google-site-verification" content="VyJfu0VJfioVV99v6tzBSMhS2j2xqmwzejPQ9vzEpWo" />
    <meta name="msvalidate.01" content="B5AA590E7B9C03956A6F7DEC0F776211">
    <meta name="baidu-site-verification" content="code-ZxFK3f4pfb" /> -->

    <!-- end SEO -->

    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <script>
        document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/main.css">
    <meta http-equiv="cleartype" content="on">
    <head>
        <base target="_blank">
    </head>

    <link rel="icon" href="images/favicon.ico" >

    <meta name="msapplication-TileColor" content="#000000">
    <meta name="msapplication-TileImage" content="images/mstile-144x144.png?v=M44lzPylqQ">
    <meta name="msapplication-config" content="images/browserconfig.xml?v=M44lzPylqQ">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="assets/css/academicons.css" />

    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

    <!-- end custom head snippets -->

</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XG8Z83SNY5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XG8Z83SNY5');
</script>

<body>
    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
        <div class="masthead__inner-wrap">
            <div class="masthead__menu">
                <nav id="site-nav" class="greedy-nav">
                    <button><div class="navicon"></div></button>
                    <ul class="visible-links">
                        <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="#about-me">Homepage</a></li>
                        <li class="masthead__menu-item"><a href="/#about-me">About Me</a></li>
                        <li class="masthead__menu-item"><a href="/#-news">News</a></li>
                        <li class="masthead__menu-item"><a href="/#-publications">Publications</a></li>
                        <!-- <li class="masthead__menu-item"><a href="/#-honors-and-awards">Honors and Awards</a></li> -->
                        <li class="masthead__menu-item"><a href="/#-educations">Educations</a></li>
                        <!-- <li class="masthead__menu-item"><a href="/#-cv">CV</a></li> -->
                        <!-- <li class="masthead__menu-item"><a href="/#-invited-talks">Invited Talks</a></li>
                        <li class="masthead__menu-item"><a href="/#-internships">Internships</a></li> -->
                    </ul>
                    <ul class="hidden-links hidden"></ul>
                </nav>
            </div>
        </div>
    </div>

    <div id="main" role="main">
        <div class="sidebar sticky">
            <div itemscope itemtype="http://schema.org/Person" class="profile_box">

                <div class="author__avatar">
                    <img src="images/smile.jpg" class="author__avatar" alt="Jieming Cui">
                </div>

                <div class="author__content">
                    <h3 class="author__name">Jieming Cui</h3>
                    <p class="author__bio">Peking University</p>
                </div>

                <div class="author__urls-wrapper">
                    <!-- <button class="btn btn--inverse">More Info & Contact</button> -->
                    <ul class="author__urls social-icons">
                        <li>
                            <div style="white-space: normal; margin-bottom: 1em;">PhD student in Peking University. Focusing on computer vision, robotics, and biology.</div>
                        </li>
                        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Beijing </li>
                        <li><a href="mailto:jeremy.cuij@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
                        <!-- <li><a href="https://www.linkedin.com/in/rayeren"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li> -->
                        <li><a href="https://dblp.org/pid/336/7638.html"><i class="ai ai-dblp ai-fw" aria-hidden="true"></i> DBLP</a></li>
                        <li><a href="https://github.com/jiemingcui"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
                        <li><a href="https://scholar.google.com/citations?hl=zh-CN&user=9LcNpvYAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
                        <li><a href="https://orcid.org/0000-0001-5189-7266"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
                    </ul>
                    <div class="author__urls_sm">
                        <a href="mailto:jeremy.cuij@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a>
                        <!-- <a href="https://www.linkedin.com/in/rayeren"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i></a> -->
                        <a href="https://dblp.org/pid/336/7638.html"><i class="ai ai-dblp ai-fw" aria-hidden="true"></i></a>
                        <a href="https://github.com/jiemingcui"><i class="fab fa-fw fa-github" aria-hidden="true"></i></a>
                        <a href="https://scholar.google.com/citations?hl=zh-CN&user=9LcNpvYAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i></a>
                        <a href="https://orcid.org/0000-0001-5189-7266"><i class="ai ai-orcid-square ai-fw"></i></a>
                    </div>
                </div>
            </div>


        </div>
        <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
            <meta itemprop="headline" content="">
            <div class="page__inner-wrap">
                <section class="page__content" itemprop="text">
                    <p><span class="anchor" id="about-me"></span> 
                        I am currently a first-year Ph.D. student at the Institute of Artificial Intelligence at Peking University, 
                        where I'm part of both the  <a href="https://pku.ai/">CoRe Lab</a> and the General Vision Lab. 
                        Additionally, I'm undertaking an internship at <a href="https://bigai.ai/">BIGAI</a> under the guidance of  <a href="http://tengyu.ai/">Tengyu Liu</a>, <a href="https://siyuanhuang.com/">Siyuan Huang</a>, and <a href="https://yzhu.io/">Yixin Zhu</a>. 
                    </p>
                    <p>   
                        My research focuses on human motion generation, robotics, scene understanding, and leveraging AI for scientific discovery, particularly in the field of biology. Moving forward, my research will focus on how embodied agents can execute actions based on open-vocabulary instructions within real-world environments.
                    </p>

                    <p>I graduated from Siyuan Class, Beijing Jiaotong Univeristy (北京交通大学思源班) with a bachelor’s degree and from the Beihang University
                        with a master’s degree, advised by <a href="https://shi.buaa.edu.cn/08114/zh_CN/index.htm">Guizhen Yu</a> and <a href="https://www.buaa.edu.cn/info/1544/12223.htm">Yunpeng Wang</a>. 
                    </p>

                    <!-- <p>I won the <a href="https://baike.baidu.com/item/%E7%99%BE%E5%BA%A6%E5%A5%96%E5%AD%A6%E9%87%91/9929412">Baidu Scholarship</a> (10 candidates worldwide each year) and <a href="https://ur.bytedance.com/scholarship">ByteDance Scholars Program</a>                        (10 candidates worldwide each year) in 2020 and was selected as one of <a href="https://mp.weixin.qq.com/s?__biz=MzA4NzQ5MTA2NA==&amp;mid=2653639431&amp;idx=1&amp;sn=25b6368c1954419b9090840347d9a27d&amp;chksm=8be75b90bc90d286a5af3ef8e610e822d705dc3cf4382b45e3f14489f3e7ec4fd8c95ed0eceb&amp;mpshare=1&amp;scene=2&amp;srcid=0511LMlj9Qv9DeIZAjMjYAU9&amp;sharer_sharetime=1620731348139&amp;sharer_shareid=631c113940cb81f34895aa25ab14422a#rd">the top 100 AI Chinese new stars</a>                        and AI Chinese New Star Outstanding Scholar (10 candidates worldwide each year).</p> -->

                    <!-- <p>My research interest includes speech synthesis, neural machine translation and automatic music generation. I have published 50+ papers <a href="https://scholar.google.com/citations?user=4FA6C0AAAAAJ"><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&amp;url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2FRayeRen%2Frayeren.github.io@google-scholar-stats%2Fgs_data_shieldsio.json&amp;labelColor=f6f6f6&amp;color=9cf&amp;style=flat&amp;label=citations" /></a>                        at the top international AI conferences such as NeurIPS, ICML, ICLR, KDD.</p> -->

                    <!-- <p>To promote the communication among the Chinese ML &amp; NLP community, we (along with other 11 young scholars worldwide) founded the <a href="https://space.bilibili.com/168887299">MLNLP community</a> in 2021. I am honored to be one
                        of the chairs of the MLNLP committee.</p> -->

                    <!-- <p>If you like the template of this homepage, welcome to star and fork my open-sourced template version <a href="https://github.com/RayeRen/acad-homepage.github.io">AcadHomepage <img src="https://img.shields.io/github/stars/RayeRen/acad-homepage.github.io?style=social" alt="" /></a>.</p> -->

                    <h1 id="-news">🔥 News</h1>
                    <ul>
                        <li><em>2024.03</em>: 🎉 One demo is accepted by 3DV 2024 demo track</li>
                        <li><em>2024.02</em>: 🎉 One paper is accepted by CVPR 2024</li>
                        <li><em>2023.09</em>: One paper is accepted by NeurIPS 2023</li>
                        <li><em>2023.09</em>: Enrolled to pursue a Ph.D. degree in the field of Artificial Intelligence.</li>
                        <li><em>2023.06</em>: One paper is accepted by ICCV 2023</li>
                    </ul>

                    <h1 id="-publications">📝 Publications</h1>
                    <div class="paper-box">
                        <div class="paper-box-image">
                            <div>
                                <div class="badge bg-danger">CVPR 2024</div>
                                <img src="images/anyskill.gif" alt="sym" width="100%"/>
                            </div>
                        </div>
                        <div class="paper-box-text">
                            <p><strong>AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents</strong> <br />
                                <strong>Jieming Cui*</strong>, <a href="http://tengyu.ai/" style="color : #696969;">Tengyu Liu*</a>, <a style="color : #696969;">Nian Liu*</a>, <a href="https://www.yangyaodong.com/" style="color : #696969;">Yaodong Yang</a>, <a href="https://yzhu.io/" style="color : #696969;">Yixin Zhu</a><span>†</span>, <a href="https://siyuanhuang.com/" style="color : #696969;">Siyuan Huang</a><span>†</span></p>

                            <p><a href="https://anyskill.github.io/"><strong>Project</strong></a> / <a href="https://github.com/jiemingcui/anyskill"><strong>Code</strong></a> / <a href="https://www.youtube.com/watch?v=QojOdY2_dTQ"><strong>Video</strong></a>  / <a href="https://arxiv.org/abs/2403.12835"><strong>Paper</strong></a> </p>

                            <p>
                                We propose <span class="title is-6">AnySkill</span>, a novel hierarchical method that <b>learns physically plausible interactions following open-vocabulary instructions</b>. 
                                An important feature of our method is the use of image-based rewards for the high-level policy, which allows the agent to <b>learn interactions with objects without manual reward engineering</b>. 
                            </p>
                        </div>
                    </div>

                    <div class="paper-box">
                        <div class="paper-box-image">
                            <div>
                                <div class="badge bg-danger">NeurIPS 2023</div>
                                <img src="images/probio.png" alt="sym" width="100%"/>
                            </div>
                        </div>
                        <div class="paper-box-text">
                            <p><strong>ProBio: A Protocol-guided Multimodal Dataset for Molecular Biology Lab </strong> <br />
                                <strong>Jieming Cui*</strong>, <a style="color : #696969;">Ziren Gong* </a>, <a href="https://buzz-beater.github.io/" style="color : #696969;">Baoxiong Jia*</a>, <a href="https://siyuanhuang.com/" style="color : #696969;">Siyuan Huang</a>, <a href="https://zilongzheng.github.io/" style="color : #696969;">Zilong Zheng</a><span>†</span>, <a href="https://majianzhu.com/" style="color : #696969;">Jianzhu Ma</a><span>†</span>, <a href="https://yzhu.io/" style="color : #696969;">Yixin Zhu</a><span>†</span> </p>

                            <p><a href="https://probio-dataset.github.io/"><strong>Project</strong></a> / <a href="https://github.com/jiemingcui/probio/"><strong>Code</strong></a> / <a href="https://vimeo.com/898064557"><strong>Video</strong></a>  / <a href="https://arxiv.org/abs/2311.00556"><strong>Paper</strong></a> / <a href="https://mp.weixin.qq.com/s/R_N9K0maP-SRw4CC9JoH2A"><strong>北大AI院官微</strong></a> </p>

                            <p>
                                We first curate a comprehensive multimodal dataset, named <span class="title is-6">ProBio</span>, as an initial step towards monitoring system. 
                                This dataset comprises fine-grained hierarchical annotations intended for the purpose of studying activity understanding in Biology lab.</p>
                        </div>
                    </div>

                    <div class="paper-box">
                        <div class="paper-box-image">
                            <div>
                                <div class="badge bg-danger">ICCV 2023</div>
                                <img src="images/chairs.png" alt="sym" width="100%"/>
                            </div>
                        </div>
                        <div class="paper-box-text">
                            <p><strong>Full-Body Articulated Human-Object Interaction</strong> <br />
                                <a href="https://jnnan.github.io/" style="color : #696969;">Nan Jiang*</a>, <a href="http://tengyu.ai/" style="color : #696969;">Tengyu Liu*</a>, <a style="color : #696969;">Zhexuan Cao</a>, <strong>Jieming Cui</strong>, <a href="https://hughw19.github.io/" style="color : #696969;">He Wang</a>, <a href="https://yzhu.io/" style="color : #696969;">Yixin Zhu</a><span>†</span>, <a href="https://siyuanhuang.com/" style="color : #696969;">Siyuan Huang</a><span>†</span></p>

                            <p><a href="https://jnnan.github.io/project/chairs/"><strong>Project</strong></a> / <a href="https://github.com/jnnan/chairs"><strong>Code</strong></a> / <a href="https://arxiv.org/abs/2212.10621"><strong>Paper</strong></a> </p>

                            <p>
                                We present CHAIRS, a large-scale motion-captured f-AHOI dataset, consisting of 16.2 hours of versatile interactions between 46 participants and 74 articulated and rigid sittable objects. CHAIRS provides 3D meshes of both humans and articulated objects during the entire interactive process, as well as realistic and physically plausible full-body interactions.
                            </p>
                        </div>
                    </div>

                    <!-- <div class="paper-box">
                        <div class="paper-box-image">
                            <div>
                                <div class="badge bg-danger">ICCV 2023</div>
                                <img src="images/gru.png" alt="sym" width="100%"/>
                            </div>
                        </div>
                        <div class="paper-box-text">
                            <p><strong>Forecasting Freeway On-Ramp Lane-Changing Behavior Based on GRU</strong> <br />
                                <strong>Jieming Cui*</strong>, <a href="https://shi.buaa.edu.cn/08114/zh_CN/index.htm" style="color : #696969;">Guizhen Yu* </a>, <a href="https://qyy.buaa.edu.cn/info/2135/4448.htm" style="color : #696969;">Bin Zhou</a>, <a style="color : #696969;">Qiujun Liu</a>, <a style="color : #696969;">Zhengguo Guan</a><span>†</span> </p>
                            <p> <a href="https://ascelibrary.org/doi/abs/10.1061/JTEPBS.0000598"><strong>Paper</strong></a> </p>
                            <p>
                                A model based on the Gated Recurrent Unit (GRU) is proposed in this study for freeway on-ramp lane-changing behavior forecasting. One specific feature of the model is that it enables the filtering out of the lateral oscillation behavior and helps enhance forecast accuracy. 
                            </p>
                        </div>
                    </div> -->
                    <li><code class="language-plaintext highlighter-rouge">ASCE 2021</code> 
                        <a href="https://ascelibrary.org/doi/abs/10.1061/JTEPBS.0000598">Forecasting Freeway On-Ramp Lane-Changing Behavior Based on GRU</a>, 
                        <strong>Jieming Cui*</strong>, <a href="https://shi.buaa.edu.cn/08114/zh_CN/index.htm" style="color : #696969;">Guizhen Yu* </a>, <a href="https://qyy.buaa.edu.cn/info/2135/4448.htm" style="color : #696969;">Bin Zhou</a>, <a style="color : #696969;">Qiujun Liu</a>, <a style="color : #696969;">Zhengguo Guan</a><span>†</span> </p>

                    </li>

                    <li><code class="language-plaintext highlighter-rouge">SAE 2021</code> 
                        <a href="https://www.sae.org/publications/technical-papers/content/2021-01-5031/">Three-Dimensional Object Detection Based on Deep Learning in Enclosed Scenario</a>, 
                        <strong>Jieming Cui*</strong>, <a href="https://shi.buaa.edu.cn/08114/zh_CN/index.htm" style="color : #696969;">Guizhen Yu* </a>, <a style="color : #696969;">Na Zhang</a>, <a href="https://teacher.buaa.edu.cn/wangzhangyu/zh_CN/index/193995/list/index.htm" style="color : #696969;">Zhangyu Wang</a></p>
                    </li>

                    <!-- <h1 id="-honors-and-awards">🎖 Honors and Awards</h1>
                    <ul>
                        <li><em>2021.10</em> Tencent Scholarship (Top 1%)</li>
                        <li><em>2021.10</em> National Scholarship (Top 1%)</li>
                        <li><em>2020.12</em> <a href="https://baike.baidu.com/item/%E7%99%BE%E5%BA%A6%E5%A5%96%E5%AD%A6%E9%87%91/9929412">Baidu Scholarship</a> (10 students in the world each year)</li>
                        <li><em>2020.12</em> <a href="https://mp.weixin.qq.com/s?__biz=MzA4NzQ5MTA2NA==&amp;mid=2653639431&amp;idx=1&amp;sn=25b6368c1954419b9090840347d9a27d&amp;chksm=8be75b90bc90d286a5af3ef8e610e822d705dc3cf4382b45e3f14489f3e7ec4fd8c95ed0eceb&amp;mpshare=1&amp;scene=2&amp;srcid=0511LMlj9Qv9DeIZAjMjYAU9&amp;sharer_sharetime=1620731348139&amp;sharer_shareid=631c113940cb81f34895aa25ab14422a#rd">AI Chinese new stars</a>                            (100 worldwide each year)</li>
                        <li><em>2020.12</em> <a href="https://mp.weixin.qq.com/s?__biz=MzA4NzQ5MTA2NA==&amp;mid=2653639431&amp;idx=1&amp;sn=25b6368c1954419b9090840347d9a27d&amp;chksm=8be75b90bc90d286a5af3ef8e610e822d705dc3cf4382b45e3f14489f3e7ec4fd8c95ed0eceb&amp;mpshare=1&amp;scene=2&amp;srcid=0511LMlj9Qv9DeIZAjMjYAU9&amp;sharer_sharetime=1620731348139&amp;sharer_shareid=631c113940cb81f34895aa25ab14422a#rd">AI Chinese New Star Outstanding Scholar</a>                            (10 candidates worldwide each year)</li>
                        <li><em>2020.12</em> <a href="https://ur.bytedance.com/scholarship">ByteDance Scholars Program</a> (10 students in China each year)</li>
                        <li><em>2020.10</em> Tianzhou Chen Scholarship (Top 1%)</li>
                        <li><em>2020.10</em> National Scholarship (Top 1%)</li>
                        <li><em>2015.10</em> National Scholarship (Undergraduate) (Top 1%)</li>
                    </ul> -->

                    <h1 id="-educations">📖 Educations</h1>
                    <ul>
                        <li><em>2023.09 - now</em>, PhD, Peking University, Beijing.</li>
                        <li><em>2019.09 - 2022.02</em>, Master, Beihang University, Beijing.</li>
                        <li><em>2015.09 - 2019.06</em>, Undergraduate, Beijing Jiaotong University, Beijing.</li>
                    </ul>

                    <!-- <h1 id="-invited-talks">💬 Invited Talks</h1>
                    <ul>
                        <li><em>2022.02</em>, Hosted MLNLP seminar | <a href="https://www.bilibili.com/video/BV1wF411x7qh">[Video]</a></li>
                        <li><em>2021.06</em>, Audio &amp; Speech Synthesis, Huawei internal talk</li>
                        <li><em>2021.03</em>, Non-autoregressive Speech Synthesis, PaperWeekly &amp; biendata | <a href="https://www.bilibili.com/video/BV1uf4y1t7Hr/">[video]</a></li>
                        <li><em>2020.12</em>, Non-autoregressive Speech Synthesis, Huawei Noah’s Ark Lab internal talk</li>
                    </ul> -->

                    <h1 id="-internships">💻 Internships</h1>
                    <ul>
                        <li><em>2022.02 - now</em>, <a href="https://bigai.ai/">BIGAI</a>, Beijing.</li>
                        <li><em>2021.06 - 2021.09</em>, <a href="https://mobile.amap.com/">Amap</a>, Alibaba, Beijing.</li>
                        <li><em>2020.02 - 2021.06</em>, <a href="https://www.i-tage.com/en/home/">Tage Zhixing</a>, Beijing.</li>
                    </ul>
                    
                    <!-- <div class="text-center">
                        Jieming Cui @2023 &nbsp;&nbsp;&nbsp;&nbsp; Total Visitors:
                        <a href='https://www.counter12.com'><img src='https://www.counter12.com/img-1wb07BYBZ195d6Dz-45.gif' border='0' alt='free web counter'></a><script type='text/javascript' src='https://www.counter12.com/ad.js?id=1wb07BYBZ195d6Dz'></script></div>
                    </div> -->
        
                </section>
            </div>
        </article>
    </div>

    <script src="assets/js/main.min.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-SWFCX99KQZ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', "G-SWFCX99KQZ");
    </script>


    <script>
        $(document).ready(function() {

            var gsDataBaseUrl = 'https://cdn.jsdelivr.net/gh/rayeren/rayeren.github.io@'

            $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function(data) {
                // var totalCitation = data['citedby']
                // document.getElementById('total_cit').innerHTML = totalCitation;
                var citationEles = document.getElementsByClassName('show_paper_citations')
                Array.prototype.forEach.call(citationEles, element => {
                    var paperId = element.getAttribute('data')
                    var numCitations = data['publications'][paperId]['num_citations']
                    element.innerHTML = '| Citations: ' + numCitations;
                });
            });
        })
    </script>


</body>

</html>